{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ruru22/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ruru22/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ruru22/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn as sk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import datetime\n",
    "import re\n",
    "import praw\n",
    "import jsonlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'sIXZTihLNiKiHw'\n",
    "client_secret = 'EjfAsmz5z8mDbZohe4UPYTPIZsYmOQ'\n",
    "user_agent = 'Test1'\n",
    "\n",
    "date_limits = ['2019-03-01 00:00:00', \n",
    "               '2019-06-01 00:00:00', \n",
    "               '2019-09-01 00:00:00', \n",
    "               '2020-01-01 00:00:00', \n",
    "               '2020-03-01 00:00:00', \n",
    "               '2020-06-01 00:00:00', \n",
    "               '2020-09-01 00:00:00', \n",
    "               '2021-01-01 00:00:00', \n",
    "               '2021-03-01 00:00:00', \n",
    "               '2021-06-01 00:00:00'\n",
    "            ]\n",
    "\n",
    "COUNT = len(date_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    created  \\\n",
      "360671  2018-12-31 02:25:14   \n",
      "270512  2018-12-31 02:27:21   \n",
      "112640  2018-12-31 02:27:56   \n",
      "294115  2018-12-31 02:29:05   \n",
      "214742  2018-12-31 02:29:18   \n",
      "...                     ...   \n",
      "498320  2021-04-09 21:26:18   \n",
      "427024  2021-04-09 21:26:19   \n",
      "816977  2021-04-09 21:26:20   \n",
      "144817  2021-04-09 21:26:21   \n",
      "516521  2021-04-09 21:26:28   \n",
      "\n",
      "                                                    title      id  \n",
      "360671  پسکوف: هیچ اقدامی علیه مظنونان معرفی گردیده در...  ab2og2  \n",
      "270512  One of the companies contracted by the governm...  ab2p2z  \n",
      "112640  Donald Trump: Outgoing chief of staff John Kel...  ab2p8u  \n",
      "294115  Todd Bowles Fired as Jets Head Coach After 4 S...  ab2pl2  \n",
      "214742  Macron's former aide admits using diplomatic p...  ab2pn3  \n",
      "...                                                   ...     ...  \n",
      "498320  Prince Charles Visits Queen Elizabeth II After...  mnr2wp  \n",
      "427024  Job postings hint at winners of NYC and London...  mnr2x1  \n",
      "816977  Tell Us The Most Underrated Moment From A Rom-...  mnr2xi  \n",
      "144817  15 Things From Lelo With Such Impressive Revie...  mnr2xw  \n",
      "516521  House Ethics Committee Investigating Florida G...  mnr30v  \n",
      "\n",
      "[818990 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def dfFromCSV(filename):\n",
    "    posts = pd.read_csv(filename)\n",
    "    return posts\n",
    "\n",
    "def dfToCSV(posts, filename):\n",
    "    posts.to_csv(filename, index=False)\n",
    "\n",
    "def postsFromNDJSON(filename):\n",
    "    posts = []\n",
    "    with jsonlines.open(filename) as reader:\n",
    "        for line in reader:\n",
    "            line = line[\"Item\"]\n",
    "            posts.append([line[\"created\"][\"S\"], line[\"title\"][\"S\"], line[\"id\"][\"S\"]])\n",
    "    posts = pd.DataFrame(posts,columns=['created', 'title', 'id'])\n",
    "\n",
    "    return posts\n",
    "\n",
    "def sortByTime(data):\n",
    "    data = data.sort_values(by='created')\n",
    "    return data\n",
    "\n",
    "posts = postsFromNDJSON(\"worldnews.jsonl\")\n",
    "posts = sortByTime(posts)\n",
    "posts.drop(posts.loc[posts['title'] == 'None'].index, inplace=True)\n",
    "dfToCSV(posts=posts, filename=\"worldnews.csv\")\n",
    "print(posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[39mprint\u001b[39m(idx \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m     52\u001b[0m text \u001b[39m=\u001b[39m posts[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m][idx]\n\u001b[0;32m---> 54\u001b[0m text \u001b[39m=\u001b[39m preprocess(text)\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m isEnglish(text):\n\u001b[1;32m     57\u001b[0m     lemmed\u001b[39m.\u001b[39mappend(text)\n",
      "Cell \u001b[0;32mIn[132], line 14\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens: \n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m token \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mwww\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m token:\n\u001b[0;32m---> 14\u001b[0m         words\u001b[39m.\u001b[39;49mappend(token)\n\u001b[1;32m     15\u001b[0m         \u001b[39m#print(token)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39m# Remove stopwords and lemmatize words\u001b[39;00m\n\u001b[1;32m     18\u001b[0m words \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39mlemmatize(word\u001b[39m.\u001b[39mlower()) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39misalnum() \u001b[39mand\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # remove links\n",
    "    words = []\n",
    "    for token in tokens: \n",
    "        if 'http' not in token and 'www' not in token:\n",
    "            words.append(token)\n",
    "            #print(token)\n",
    "\n",
    "    # Remove stopwords and lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    #print(words)\n",
    "\n",
    "    words_split = []\n",
    "    for word in words:\n",
    "        if isEnglish(word):\n",
    "            words_split.extend((re.split('(\\d+)',word)))\n",
    "\n",
    "    return ' '.join(words_split)\n",
    "\n",
    "def isEnglish(text):\n",
    "    try:\n",
    "        text.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def separateNumbersAlphabets(str):\n",
    "    numbers = re.findall(r'[0-9]+', str)\n",
    "    alphabets = re.findall(r'[a-zA-Z]+', str)\n",
    "    print(*numbers)\n",
    "    print(*alphabets)\n",
    "\n",
    "posts = dfFromCSV('worldnews.csv')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "lemmed = []\n",
    "\n",
    "for idx in posts.index:\n",
    "    if idx % 50000 == 0:\n",
    "        print(idx / 1000)\n",
    "    text = posts['title'][idx]\n",
    "\n",
    "    text = preprocess(text)\n",
    "\n",
    "    if isEnglish(text):\n",
    "        lemmed.append(text)\n",
    "    else:\n",
    "        lemmed.append('DELETEME')\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "print(\"Took\", stop - start, \"seconds\")\n",
    "\n",
    "posts[\"title\"] = lemmed\n",
    "\n",
    "posts.drop(posts.loc[posts['title'] == 'DELETEME'].index, inplace=True)\n",
    "posts.drop(posts.loc[posts['title'] == ''].index, inplace=True)\n",
    "\n",
    "#print(posts)\n",
    "dfToCSV(posts, 'lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n",
      "1 790 790\n",
      "Empty DataFrame\n",
      "Columns: [id, title, author, score, num_comments, text]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(chunks), \u001b[39mlen\u001b[39m(chunks[\u001b[39m0\u001b[39m]), \u001b[39mlen\u001b[39m(chunks[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     62\u001b[0m     \u001b[39mfor\u001b[39;00m idx,chunk \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chunks):\n\u001b[0;32m---> 63\u001b[0m         dfToCSV(downloadPosts(chunk), \u001b[39m\"\u001b[39m\u001b[39mcomments_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(rem) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(idx) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[39m#print(len(reduced))\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#dfToCSV(downloadPosts(reduced['id'].to_list()), \"comments.csv\")\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#dfToCSV(downloadPosts(['kljtg8']), \"comments.csv\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[159], line 27\u001b[0m, in \u001b[0;36mdownloadPosts\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     26\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfor\u001b[39;00m top_level_comment \u001b[39min\u001b[39;00m post\u001b[39m.\u001b[39;49mcomments:\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mhasattr\u001b[39m(top_level_comment, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m     29\u001b[0m         processed \u001b[39m=\u001b[39m preprocess(top_level_comment\u001b[39m.\u001b[39mbody)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/praw/models/reddit/base.py:35\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attribute\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetched:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch()\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attribute)\n\u001b[1;32m     37\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/praw/models/reddit/submission.py:712\u001b[0m, in \u001b[0;36mSubmission._fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 712\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_data()\n\u001b[1;32m    713\u001b[0m     submission_listing, comment_listing \u001b[39m=\u001b[39m data\n\u001b[1;32m    714\u001b[0m     comment_listing \u001b[39m=\u001b[39m Listing(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reddit, _data\u001b[39m=\u001b[39mcomment_listing[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/praw/models/reddit/submission.py:731\u001b[0m, in \u001b[0;36mSubmission._fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m params\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_additional_fetch_params\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m    730\u001b[0m path \u001b[39m=\u001b[39m API_PATH[name]\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfields)\n\u001b[0;32m--> 731\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reddit\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams, path\u001b[39m=\u001b[39;49mpath)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[39m=\u001b[39m _generate_arg_string(_old_args[: \u001b[39mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositional arguments for \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m will no longer be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m supported in PRAW 8.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCall this function with \u001b[39m\u001b[39m{\u001b[39;00marg_string\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(_old_args, args)), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/praw/reddit.py:941\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m ClientException(\u001b[39m\"\u001b[39m\u001b[39mAt most one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    940\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_core\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    942\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    943\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    944\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    945\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    946\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    947\u001b[0m         path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    948\u001b[0m     )\n\u001b[1;32m    949\u001b[0m \u001b[39mexcept\u001b[39;00m BadRequest \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    950\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prawcore/sessions.py:330\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    328\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mapi_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m url \u001b[39m=\u001b[39m urljoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_with_retries(\n\u001b[1;32m    331\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    332\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    333\u001b[0m     json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    334\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    335\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    336\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    337\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    338\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prawcore/sessions.py:228\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    226\u001b[0m retry_strategy_state\u001b[39m.\u001b[39msleep()\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_request(data, method, params, url)\n\u001b[0;32m--> 228\u001b[0m response, saved_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    229\u001b[0m     data,\n\u001b[1;32m    230\u001b[0m     files,\n\u001b[1;32m    231\u001b[0m     json,\n\u001b[1;32m    232\u001b[0m     method,\n\u001b[1;32m    233\u001b[0m     params,\n\u001b[1;32m    234\u001b[0m     retry_strategy_state,\n\u001b[1;32m    235\u001b[0m     timeout,\n\u001b[1;32m    236\u001b[0m     url,\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m do_retry \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    241\u001b[0m     response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m codes[\u001b[39m\"\u001b[39m\u001b[39munauthorized\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    243\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prawcore/sessions.py:185\u001b[0m, in \u001b[0;36mSession._make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     url,\n\u001b[1;32m    183\u001b[0m ):\n\u001b[1;32m    184\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rate_limiter\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m    186\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requestor\u001b[39m.\u001b[39;49mrequest,\n\u001b[1;32m    187\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_header_callback,\n\u001b[1;32m    188\u001b[0m             method,\n\u001b[1;32m    189\u001b[0m             url,\n\u001b[1;32m    190\u001b[0m             allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    191\u001b[0m             data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    192\u001b[0m             files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    193\u001b[0m             json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    194\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    195\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    196\u001b[0m         )\n\u001b[1;32m    197\u001b[0m         log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    198\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m bytes)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prawcore/rate_limit.py:34\u001b[0m, in \u001b[0;36mRateLimiter.call\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay()\n\u001b[1;32m     33\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m set_header_callback()\n\u001b[0;32m---> 34\u001b[0m response \u001b[39m=\u001b[39m request_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(response\u001b[39m.\u001b[39mheaders)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/prawcore/requestor.py:58\u001b[0m, in \u001b[0;36mRequestor.request\u001b[0;34m(self, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Issue the HTTP request capturing any errors that may occur.\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_http\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m     59\u001b[0m         \u001b[39m*\u001b[39;49margs, timeout\u001b[39m=\u001b[39;49mtimeout \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     62\u001b[0m     \u001b[39mraise\u001b[39;00m RequestException(exc, args, kwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:544\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    539\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    541\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    542\u001b[0m }\n\u001b[1;32m    543\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 544\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    546\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py:657\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    656\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    659\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    660\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    440\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    441\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    442\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    443\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    444\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    445\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    449\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    698\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    700\u001b[0m     conn,\n\u001b[1;32m    701\u001b[0m     method,\n\u001b[1;32m    702\u001b[0m     url,\n\u001b[1;32m    703\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    704\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    705\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    706\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    707\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    441\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    441\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def downloadPosts(ids):\n",
    "    reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent, check_for_async=False)\n",
    "    posts_raw = []\n",
    "\n",
    "    for idx in range(0,len(ids)):\n",
    "        ids[idx] = \"t3_\" + ids[idx]\n",
    "\n",
    "    info = reddit.info(fullnames=ids)\n",
    "\n",
    "    texts = []\n",
    "    num_comments = []\n",
    "    scores = []\n",
    "    authors = []\n",
    "    titles = []\n",
    "    idxs = []\n",
    "    used_ids = []\n",
    "    times = []\n",
    "\n",
    "    post_data = pd.DataFrame(list(zip([], titles, authors, scores, num_comments, texts)),columns=['id', 'title', 'author', 'score', 'num_comments', 'text'])\n",
    "    print(post_data)\n",
    "\n",
    "    for post in info:\n",
    "        if post.score < 100:\n",
    "            continue\n",
    "\n",
    "        text = ''\n",
    "        for top_level_comment in post.comments:\n",
    "            if(hasattr(top_level_comment, 'body')):\n",
    "                processed = preprocess(top_level_comment.body)\n",
    "                if processed is not None:\n",
    "                    text += processed + ' '\n",
    "        texts.append(text)\n",
    "        num_comments.append(len(post.comments))\n",
    "        scores.append(post.score)\n",
    "        authors.append(post.author)\n",
    "        titles.append(preprocess(post.title))\n",
    "        used_ids.append(post.id)\n",
    "        times.append(post.created_utc)\n",
    "\n",
    "    post_data = pd.DataFrame(list(zip(used_ids, times, titles, authors, scores, num_comments, texts)),columns=['id', 'time', 'title', 'author', 'score', 'num_comments', 'text'])\n",
    "\n",
    "    return post_data\n",
    "\n",
    "\n",
    "\n",
    "#reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent, check_for_async=False)\n",
    "#submission = reddit.submission('16dneuo')\n",
    "#print(len(submission.comments))\n",
    "#for top_level_comment in submission.comments:\n",
    "#    print(top_level_comment.body)\n",
    "def divide_chunks(l, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]\n",
    "\n",
    "worldnews = dfFromCSV(\"lemmatized_ascii.csv\")\n",
    "for rem in range(0,1000):\n",
    "    reduced = worldnews.iloc[[*range(rem,len(worldnews),1000)], :].copy()\n",
    "    reduced = reduced['id'].to_list()\n",
    "    chunks = list(divide_chunks(reduced, 1000))\n",
    "    print(len(chunks), len(chunks[0]), len(chunks[-1]))\n",
    "    for idx,chunk in enumerate(chunks):\n",
    "        dfToCSV(downloadPosts(chunk), \"comments_\" + str(rem) + \"_\" + str(idx) +\".csv\")\n",
    "  \n",
    "#print(len(reduced))\n",
    "#dfToCSV(downloadPosts(reduced['id'].to_list()), \"comments.csv\")\n",
    "#dfToCSV(downloadPosts(['kljtg8']), \"comments.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ab2pn3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>macron former aide admits using diplomatic pas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>pretty huge story france let give detail case ...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ab33i1</td>\n",
       "      <td>2801.0</td>\n",
       "      <td>bacteria found ancient irish soil halt growth ...</td>\n",
       "      <td>bhel_</td>\n",
       "      <td>5058</td>\n",
       "      <td>62</td>\n",
       "      <td>something muck dirt buddy mine gross wart hand...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ab36ix</td>\n",
       "      <td>3411.0</td>\n",
       "      <td>korea ban use disposable shopping bag supermarket</td>\n",
       "      <td>edwinksl</td>\n",
       "      <td>8930</td>\n",
       "      <td>81</td>\n",
       "      <td>cafe illegal serve drink paper plastic cup dri...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ab3esx</td>\n",
       "      <td>5137.0</td>\n",
       "      <td>footage show saudi hit team carrying bag belie...</td>\n",
       "      <td>AWACS-Thunderhead</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "      <td>anyone know turkey managed get audio recording...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ab3eyp</td>\n",
       "      <td>5167.0</td>\n",
       "      <td>trump worst perpetrator false information amer...</td>\n",
       "      <td>glasier</td>\n",
       "      <td>72507</td>\n",
       "      <td>35</td>\n",
       "      <td>remember said releasing jfk file still waiting...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>42</td>\n",
       "      <td>mndr89</td>\n",
       "      <td>71738407.0</td>\n",
       "      <td>pressure xinjiang china take aim overseas uigh...</td>\n",
       "      <td>edourdoo1</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "      <td>friday event official took aim database set ov...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8687</th>\n",
       "      <td>53</td>\n",
       "      <td>mne5su</td>\n",
       "      <td>71740259.0</td>\n",
       "      <td>norwegian prime minister fined police breaking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2634</td>\n",
       "      <td>26</td>\n",
       "      <td>deleted first thought norwegian good able dodg...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>51</td>\n",
       "      <td>mne6ah</td>\n",
       "      <td>71740331.0</td>\n",
       "      <td>south korea launch first homegrown supersonic ...</td>\n",
       "      <td>brownandbumpy</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>final test completed future south korea become...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>63</td>\n",
       "      <td>mnekkn</td>\n",
       "      <td>71742080.0</td>\n",
       "      <td>bike lane canada commits  400 m build sustaina...</td>\n",
       "      <td>ellalingling</td>\n",
       "      <td>106</td>\n",
       "      <td>9</td>\n",
       "      <td>putting infrastructure get  8  month long summ...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>50</td>\n",
       "      <td>mnenwf</td>\n",
       "      <td>71742479.0</td>\n",
       "      <td>kim warns north korea crisis similar deadly  9...</td>\n",
       "      <td>ouchcast</td>\n",
       "      <td>347</td>\n",
       "      <td>37</td>\n",
       "      <td>deleted bet miss meal nothing parade fix seems...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8691 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      id        time  \\\n",
       "0         0  ab2pn3         0.0   \n",
       "1         0  ab33i1      2801.0   \n",
       "2         0  ab36ix      3411.0   \n",
       "3         0  ab3esx      5137.0   \n",
       "4         0  ab3eyp      5167.0   \n",
       "...     ...     ...         ...   \n",
       "8686     42  mndr89  71738407.0   \n",
       "8687     53  mne5su  71740259.0   \n",
       "8688     51  mne6ah  71740331.0   \n",
       "8689     63  mnekkn  71742080.0   \n",
       "8690     50  mnenwf  71742479.0   \n",
       "\n",
       "                                                  title             author  \\\n",
       "0     macron former aide admits using diplomatic pas...                NaN   \n",
       "1     bacteria found ancient irish soil halt growth ...              bhel_   \n",
       "2     korea ban use disposable shopping bag supermarket           edwinksl   \n",
       "3     footage show saudi hit team carrying bag belie...  AWACS-Thunderhead   \n",
       "4     trump worst perpetrator false information amer...            glasier   \n",
       "...                                                 ...                ...   \n",
       "8686  pressure xinjiang china take aim overseas uigh...          edourdoo1   \n",
       "8687  norwegian prime minister fined police breaking...                NaN   \n",
       "8688  south korea launch first homegrown supersonic ...      brownandbumpy   \n",
       "8689  bike lane canada commits  400 m build sustaina...       ellalingling   \n",
       "8690  kim warns north korea crisis similar deadly  9...           ouchcast   \n",
       "\n",
       "      score  num_comments                                               text  \\\n",
       "0       301             5  pretty huge story france let give detail case ...   \n",
       "1      5058            62  something muck dirt buddy mine gross wart hand...   \n",
       "2      8930            81  cafe illegal serve drink paper plastic cup dri...   \n",
       "3      2022            24  anyone know turkey managed get audio recording...   \n",
       "4     72507            35  remember said releasing jfk file still waiting...   \n",
       "...     ...           ...                                                ...   \n",
       "8686    180             8  friday event official took aim database set ov...   \n",
       "8687   2634            26  deleted first thought norwegian good able dodg...   \n",
       "8688    178             9  final test completed future south korea become...   \n",
       "8689    106             9  putting infrastructure get  8  month long summ...   \n",
       "8690    347            37  deleted bet miss meal nothing parade fix seems...   \n",
       "\n",
       "      month  \n",
       "0      -0.0  \n",
       "1      -0.0  \n",
       "2      -0.0  \n",
       "3      -0.0  \n",
       "4      -0.0  \n",
       "...     ...  \n",
       "8686   27.0  \n",
       "8687   27.0  \n",
       "8688   27.0  \n",
       "8689   27.0  \n",
       "8690   27.0  \n",
       "\n",
       "[8691 rows x 9 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps = []\n",
    "for i in range(0,167):\n",
    "    temps.append(dfFromCSV('comments_' + str(i) + \"_0.csv\"))\n",
    "\n",
    "df = pd.concat(temps)\n",
    "start = df['time'].min()\n",
    "df['time'] = df['time'] - start\n",
    "df = df.sort_values(by='time')\n",
    "df['month'] = df['time'] / 2592000\n",
    "df['month'] = (df['month'] - 0.5).round()\n",
    "df = df.reset_index()\n",
    "\n",
    "dfToCSV(df, '_sorted.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
